{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc5...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "from datetime import datetime\n",
    "\n",
    "from dlchelperclass import DlcHelperClass as dhc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos\"\n",
      "Created \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/labeled-data\"\n",
      "Created \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/training-datasets\"\n",
      "Created \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/dlc-models\"\n",
      "Copying the videos\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/GH010346_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/240frames_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/RF_mapping_untracked_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/GH010342_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/1-1_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/1-2_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/smalltest_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/2-2k7-120-hand_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/GH010345_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/GH010336_converted.mp4\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/videos/squaretest_converted.mp4\n",
      "Generated \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/config.yaml\"\n",
      "\n",
      "A new project with name dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21 is created at /local/data2/LIA_LIU_PONTUS/LIA_LIU and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "# Enter your project name\n",
    "project_name = 'dlcrnet_stride32_ms5_lr_001_bs_4'\n",
    "# If you want to use labeled frames from an earlier project,\n",
    "# make sure to use the same experiment name as in the previous project.\n",
    "# Enter your experimenter name\n",
    "experimenter_name = 'conv_vid'\n",
    "# Specify where you want your project folder to be created\n",
    "work_dir = '/local/data2/LIA_LIU_PONTUS/LIA_LIU'\n",
    "# create project path\n",
    "project_path = work_dir + '/' + project_name + '-' + experimenter_name + '-' + datetime.now().strftime(\"%Y-%m-%d\")\n",
    "# video path\n",
    "videos_dir_path = '/local/data2/LIA_LIU/videos_converted'\n",
    "# Creates a list variable of all videos paths \n",
    "video_path = dhc.get_video_paths(path=videos_dir_path)\n",
    "# Create project\n",
    "deeplabcut.create_new_project(\n",
    "    project=project_name,\n",
    "    experimenter=experimenter_name,\n",
    "    videos=video_path,\n",
    "    working_directory=work_dir,\n",
    "    copy_videos=True\n",
    ")\n",
    "\n",
    "# Config yaml path\n",
    "config_path = project_path + '/config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize paths (For loading existing project)\n",
    "# skip this cell if you created a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your project path\n",
    "project_path = \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001-conv_vid-2024-11-21\"\n",
    "# Creates path for config file and videos\n",
    "config_path, video_path = dhc.get_config_and_video_paths(project_path=project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frames for labeling, amount of images and train/test ratio defined in config.yaml\n",
    "deeplabcut.extract_frames(config_path=config_path, video_path=video_path, mode='automatic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use napari for labeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates CSV and h5 files needed for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/labeled-data/GH010346_converted/CollectedData_conv_vid.h5  not found (perhaps not annotated).\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/labeled-data/GH010345_converted/CollectedData_conv_vid.h5  not found (perhaps not annotated).\n",
      "/local/data2/LIA_LIU_PONTUS/LIA_LIU/dlcrnet_stride32_ms5_lr_001_bs_4-conv_vid-2024-11-21/labeled-data/GH010336_converted/CollectedData_conv_vid.h5  not found (perhaps not annotated).\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9,\n",
       "  1,\n",
       "  (array([382, 487, 351,  14, 145, 422, 753, 253, 175, 231,  31, 235, 764,\n",
       "          563, 156, 215, 441, 435, 103, 386, 193, 767, 734, 662,  27, 636,\n",
       "          530, 627, 457, 643, 501, 701,  55, 776, 635, 586, 781,  85, 356,\n",
       "           40, 122, 362, 666,  75, 476,   8, 693, 239, 365, 150, 285, 604,\n",
       "          647, 485, 590, 409, 283, 578, 268,  79,   1, 313, 483, 490, 676,\n",
       "          250, 397, 619, 614, 558, 366, 691, 673, 502, 644, 236, 592, 279,\n",
       "          251, 620, 315, 399, 517, 567, 724, 363, 113, 413, 252, 350, 638,\n",
       "           18, 196, 425, 571, 293, 575, 369,  50, 271, 751, 760, 710, 415,\n",
       "           39, 142, 172, 454, 739,  10, 584,  68, 214, 364, 242, 686, 327,\n",
       "          471,   2, 775, 625, 230, 202, 473, 447, 580, 258, 261, 774, 374,\n",
       "          389, 249, 708, 200, 243, 577, 337,  71,  49, 424, 210, 116,  37,\n",
       "          406,  48, 632, 319, 294, 241, 222, 162,  76,  64, 622,  52, 491,\n",
       "          597, 432, 519, 564, 773, 402, 750, 680, 118,  12, 157, 628, 263,\n",
       "          306, 316, 358,  97, 540, 630, 181, 715, 704, 401, 534, 338, 609,\n",
       "          521,  17, 649, 573, 532, 355, 312, 718, 255, 170, 187, 765, 204,\n",
       "           45, 605,  62,  78, 354, 443, 646, 140, 198, 719, 652, 127, 240,\n",
       "          390, 712, 144, 278,  21, 626, 587,  35, 495, 159, 318,  77, 385,\n",
       "          266, 778, 109, 247, 419, 101, 367, 272,  92, 720, 670, 557, 733,\n",
       "          346, 380, 770, 267, 211, 317, 165, 504, 188, 345, 711,  34, 566,\n",
       "          434, 779, 375, 494, 650, 155, 449, 392, 408, 334,  66, 301, 452,\n",
       "          161, 484, 299, 522, 303, 538, 403, 331, 499, 229, 721, 654, 489,\n",
       "          740, 602, 694,  15, 245, 302,   6, 333, 352, 104, 769, 418, 692,\n",
       "           90, 467, 417, 546, 218, 576, 310, 205, 404, 190, 513, 672, 194,\n",
       "          506, 132, 233, 173, 178, 756, 608, 206, 667,  96, 671, 344, 458,\n",
       "           89, 462, 179,   0,  46, 171, 623, 725, 107, 133, 612, 223, 475,\n",
       "          102, 545, 108, 213, 511, 416, 246, 500, 436, 125, 474, 744, 428,\n",
       "          772, 224,  26, 493, 482, 548, 395,   3, 134, 325, 505, 186, 596,\n",
       "          295, 655, 618, 616, 703, 225, 641, 330, 722, 332, 759, 601, 531,\n",
       "          745,  63, 526, 615, 360, 407, 588, 112, 479, 687,  20,  65, 298,\n",
       "          126, 259, 634, 695, 412, 729, 339, 384, 656, 137, 105,   7, 342,\n",
       "          716, 309, 651, 542, 185, 533, 353, 481, 153,  54,  30, 742, 696,\n",
       "          100, 518, 645, 738, 237, 679,  56, 400,  60, 516, 262, 453, 264,\n",
       "          726, 478, 208, 391, 497, 468, 167,  38, 492, 674, 640, 300, 520,\n",
       "          535, 664, 163, 124, 154, 336,  59, 642, 304, 730, 613, 343, 460,\n",
       "          451, 311, 427, 496, 465, 158,  51, 561, 698, 527, 361, 477, 736,\n",
       "          219, 524, 308,  74, 282, 572, 348, 529,   4, 780, 437, 463, 603,\n",
       "          536, 688,   5, 141, 569, 456, 135, 685, 378, 699,  22, 706, 466,\n",
       "          276, 284, 470, 270, 426, 746, 281, 420, 220, 777, 320, 439, 372,\n",
       "          120,  81, 766,  13, 503, 455, 757, 748, 160, 762, 238, 379, 523,\n",
       "          549, 440, 556, 583, 195, 191, 164, 106,  16, 553, 329, 480, 498,\n",
       "          682, 405, 582,  93, 433,  83, 661, 689, 414, 570, 568, 713, 322,\n",
       "          357,  69, 514, 509, 340, 221, 727, 146, 289,  29, 114, 508, 631,\n",
       "          758, 176, 168, 347, 376, 593, 683, 668, 771, 189, 136, 446, 658,\n",
       "          254, 690, 290, 735, 663, 232,  33,  88,  44, 341,  61, 747, 199,\n",
       "          429, 585, 394, 297,  73, 393, 547, 579, 541, 669, 653, 749, 217,\n",
       "          539, 648, 421, 138, 212, 700, 657, 678, 717, 234,  67,  24, 381,\n",
       "          216, 129, 349, 111, 166, 207, 438, 552, 274, 665, 591, 624, 525,\n",
       "          287, 469, 326, 121, 507, 228, 595, 445, 117, 464,  25, 110, 149,\n",
       "          152, 528, 621, 461, 598, 139, 260, 323, 702, 248, 450, 410, 607,\n",
       "           19, 328, 296, 269, 226,  94, 515, 637, 280, 286, 589, 728, 444,\n",
       "          184, 371, 782, 761, 275, 731, 182,  32,  80, 307,  11,  43,  86,\n",
       "           36,  58,  41, 411, 562, 209, 148, 594, 123, 574,  98, 377, 130,\n",
       "           23, 681, 555, 370, 512, 383, 201, 368, 554, 610, 387, 292, 256,\n",
       "          606, 197,  95, 752, 737, 169, 581, 305, 560, 373, 227, 660, 143,\n",
       "          180, 131]),\n",
       "   array([743,  47, 324, 203,  84, 633, 565, 611, 398,  91,  82, 430, 119,\n",
       "          291,  57, 321, 257, 741, 442,  42, 617, 388, 335, 273, 488, 550,\n",
       "           53, 732, 128,  28, 183, 459, 510, 675, 151, 244, 714, 543, 544,\n",
       "          639, 697, 265, 288, 423, 147, 659, 177,  99, 448, 431, 709, 755,\n",
       "          115,  72, 537, 677, 768, 174,  87, 551, 486, 705, 314, 396, 600,\n",
       "          472,  70, 599, 754, 277, 723,   9, 359, 707, 763, 192, 629, 559,\n",
       "          684])))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config=config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network(config_path, maxiters=1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates training_stats.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for plotting losses\n",
    "deeplabcut.evaluate_network(config_path, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes prediction on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new videos with the models predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates likelihood.txt file and loss/vall_loss plot\n",
    "dhc.save_mean_likelihood_to_file(project_path=project_path)\n",
    "dhc.plot_loss_to_png(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract outlier frames and re-labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(config=config_path,\n",
    "                                   shuffle=1,\n",
    "                                  automatic=True,\n",
    "                                  videos=video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the DeepLabCut GUI to manually correct labels\n",
    "# Launch the GUI to manually adjust labels on the extracted frames\n",
    "deeplabcut.refine_labels(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.merge_datasets(config=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new training dataset that includes the updated labels\n",
    "# This prepares the training files with the corrected labels for training\n",
    "deeplabcut.create_training_dataset(config=config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have run the following code line before:\n",
    "# * deeplabcut.analyze_videos(project_path, video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the updated dataset\n",
    "# Use transfer learning to improve the existing model with the new data\n",
    "deeplabcut.train_network(project_path, shuffle=1, displayiters=100, saveiters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-evaluate performance on the updated model\n",
    "# Analyze the videos again to check if model accuracy has improved after retraining\n",
    "deeplabcut.analyze_videos(project_path, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/untrained_videos/dlcrnet_stride32_ms5_test/GH010345_converted.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace with your actual old projects directory\n",
    "old_project_path = \"/local/data2/old_projects/\"\n",
    "\n",
    "# Iterate through each project in the old_project_path\n",
    "for project in os.listdir(old_project_path):\n",
    "    project_path = os.path.join(old_project_path, project)  # Construct full project path\n",
    "\n",
    "    # Check if the path is a directory (to ensure it's a project folder)\n",
    "    if os.path.isdir(project_path):\n",
    "        # Call methods from your helper class\n",
    "        #dhc.save_mean_likelihood_to_file(project_path=project_path)\n",
    "        dhc.plot_loss_to_png(project_path)\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
