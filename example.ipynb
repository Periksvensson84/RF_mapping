{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "from datetime import datetime\n",
    "\n",
    "from dlchelperclass import DlcHelperClass as dhc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your project name\n",
    "project_name = 'one_vid_res50'\n",
    "# If you want to use labeled frames from an earlier project,\n",
    "# make sure to use the same experiment name as in the previous project.\n",
    "# Enter your experimenter name\n",
    "experimenter_name = 'liu'\n",
    "# Specify where you want your project folder to be created\n",
    "work_dir = '/local/data2/LIA_LIU_PONTUS/LIA_LIU'\n",
    "# create project path\n",
    "project_path = work_dir + '/' + project_name + '-' + experimenter_name + '-' + datetime.now().strftime(\"%Y-%m-%d\")\n",
    "# video path\n",
    "videos_dir_path = '/local/data2/Cropped_video'\n",
    "# Creates a list variable of all videos paths \n",
    "video_path = dhc.get_video_paths(path=videos_dir_path)\n",
    "# Create project\n",
    "deeplabcut.create_new_project(\n",
    "    project=project_name,\n",
    "    experimenter=experimenter_name,\n",
    "    videos=video_path,\n",
    "    working_directory=work_dir,\n",
    "    copy_videos=True\n",
    ")\n",
    "\n",
    "# Config yaml path\n",
    "config_path = project_path + '/config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize paths (For loading existing project)\n",
    "# skip this cell if you created a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your project path\n",
    "project_path = \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/one_vid_stride32-liu-2024-11-25\"\n",
    "# Creates path for config file and videos\n",
    "config_path, video_path = dhc.get_config_and_video_paths(project_path=project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frames for labeling, amount of images and train/test ratio defined in config.yaml\n",
    "\n",
    "# \"Do you want to extract (perhaps additional) frames for video:\" answer yes\n",
    "\n",
    "deeplabcut.extract_frames(config=config_path, mode='automatic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use napari for labeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates CSV and h5 files needed for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9,\n",
       "  1,\n",
       "  (array([14, 12,  7,  4, 18, 11, 22,  6, 23, 10, 13,  1, 24,  3,  2,  0, 17,\n",
       "          15,  5, 21, 16, 19]),\n",
       "   array([20,  9,  8])))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config=config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network(config_path, maxiters=1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates training_stats.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for plotting losses\n",
    "deeplabcut.evaluate_network(config_path, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes prediction on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new videos with the models predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates likelihood.txt file and loss/vall_loss plot\n",
    "dhc.save_mean_likelihood_to_file(project_path=project_path)\n",
    "dhc.plot_loss_to_png(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract outlier frames and re-labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(config=config_path,\n",
    "                                   shuffle=1,\n",
    "                                  automatic=True,\n",
    "                                  videos=video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the DeepLabCut GUI to manually correct labels\n",
    "# Launch the GUI to manually adjust labels on the extracted frames\n",
    "deeplabcut.refine_labels(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.merge_datasets(config=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new training dataset that includes the updated labels\n",
    "# This prepares the training files with the corrected labels for training\n",
    "deeplabcut.create_training_dataset(config=config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have run the following code line before:\n",
    "# * deeplabcut.analyze_videos(project_path, video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the updated dataset\n",
    "# Use transfer learning to improve the existing model with the new data\n",
    "deeplabcut.train_network(project_path, shuffle=1, displayiters=100, saveiters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-evaluate performance on the updated model\n",
    "# Analyze the videos again to check if model accuracy has improved after retraining\n",
    "deeplabcut.analyze_videos(project_path, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/untrained_videos/CROP_stride32_lr0001_bs_1/GH010336_converted_2.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path, videos=video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace with your actual old projects directory\n",
    "old_project_path = \"/local/data2/old_projects/\"\n",
    "\n",
    "# Iterate through each project in the old_project_path\n",
    "for project in os.listdir(old_project_path):\n",
    "    project_path = os.path.join(old_project_path, project)  # Construct full project path\n",
    "\n",
    "    # Check if the path is a directory (to ensure it's a project folder)\n",
    "    if os.path.isdir(project_path):\n",
    "        # Call methods from your helper class\n",
    "        dhc.save_mean_likelihood_to_file(project_path=project_path)\n",
    "        dhc.plot_loss_to_png(project_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get likelihood from predicted video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "h5_path = \"/local/data2/LIA_LIU_PONTUS/LIA_LIU/untrained_videos/CROP_stride32_lr0001_bs_1/GH010336_converted_2DLC_DlcrnetStride32Ms5_dlcrnet_stride32_ms5_lr_0001_bs_1Nov21shuffle1_snapshot_100.h5\"\n",
    "df = pd.read_hdf(h5_path)\n",
    "df.columns = [f\"{bodypart}_{coord}\" for bodypart, coord in zip(df.columns.get_level_values(1), df.columns.get_level_values(2))]\n",
    "df_monofil = df.loc[:, df.columns.str.startswith(('FR', 'FG', 'FB')) & ~df.columns.str.endswith('likelihood')]\n",
    "df_square = df.loc[:, df.columns.str.startswith(('Top_left', 'Top_right', 'Bottom_left', 'Bottom_right')) & ~df.columns.str.endswith('likelihood')]\n",
    "df_likelihoods = df.loc[:, df.columns.str.endswith('likelihood')]\n",
    "overall_average = df_likelihoods.mean().mean()\n",
    "print(\"Overall Average Likelihood:\", overall_average)\n",
    "bodypart_means = df_likelihoods.mean(axis=0)\n",
    "print(\"Mean likelihood for each body part:\")\n",
    "print(bodypart_means)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
